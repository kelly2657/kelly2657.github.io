---
title: '[Blog]핸즈온 머신러닝 연습문제 1장, 4장'
layout: single
categories:
  - Python
tag:
  - Blog
  - machinelearning
toc: true
toc_label: "on this page"
toc_sticky: true
---
# Chap1.
1. __머신러닝이란?__
> 명시적인 프로그래밍 없이 컴퓨터가 스스로 데이터로부터 학습하는 능력을 갖게하는 연구분야

2. __머신러닝이 도움을 줄 수 있는 4가지 문제는?__
> 이미지 분석, 자연어 처리, 회귀, 군집화

     머신러닝의 장점 
     - 데이터 마이닝 가능
     - 전통적 방식으로 해결 어려운 복잡한 문제 해결 가능
     - 새로운 데이터로 시스템에 쉽게 재훈련시킬 수 있음

3. __레이블된 훈련셋이란?__
> 각 샘플에 대해 원하는 레이블 담고있는 훈련셋

4. __흔한 지도학습작업 두가지는 무엇인가__
> 분류: 값의 소속을 예측한다   
> 회귀 : 값을 예측한다

5. 흔한 비지도 학습 작업 네 가지는 무엇인가
> 계층군집, 시각화, 차원축소, 연관규칙

6. 사전 정보가 없는 여러 지형에서 로봇을 걷게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있을까
> 강화학습

7. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 할까
> 어떻게 정의할지 모른다면 군집화알고리즘을 사용하고 안다면 분류알고리즘을 사용한다.

8. __스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제인가__
> 지도학습문제이다.(분류)

9. 온라인학습 시스템이란 무엇인가
> 변화하는 데이터와 자율 시스템에 빠르게 적응하고 많은 양의 데이터 훈련시키는 시스템이다

10. __외부 메모리학습이 무엇인가__
> 특성이나 훈련데이터가 많아 메모리에 한번에 담을 수 없는 경우 대용량의 데이터를 다루기위해 사용된다.

11. 예측을 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가
> 사례기반학습이다. 유사도 측정해 학습된 샘플 중 가장 비슷한 걸로 예측한다.

12. __모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있나__
> 모델파라미터는 모델 훈련중 학습되는 파라미터이다(선형모델의 기울기).    
> 학습 알고리즘의 하이퍼파라미터는 훈련 전에 미리 지정되어 훈련에 영향을 받지 않는다(규제의 정도).
  
13. __모델 기반 알고리즘이 찾는 것은 무엇인가? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가? 예측은 어떻게 만드나?__
> 비용함수를 최소화하고 효용함수를 회대화하는 파라미터를 찾는다.       
> 비용함수를 측정하고 비용함수를 최소화하며 모델을 훈련한다.   
> 알고리즘이 찾은 파라미터를 사용하는 모델의 예측함수에 훈련데이터를 넣어 예측한다.

14. __머신러닝의 네가지 주요도전과제는 무엇인가__
> 모델이 편향, 잡음에 민감하게 반응하는 것을 막기위해 데이터 정제를 적절히 해내는것,   
> 모델이 충분한 데이터를 가지고 훈련해 과소적합이나 과대적합이 발생하지 않도록 하기 위해 데이터를 잘 구하는 것, 전처리를 적절히 해내는것이 필요하다.

15. __모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 것일까? 해결할 수 있는 방법은 무엇인가?__
> 훈련셋 검증은 우수하지만 교차검증점수는 낮다면 과대적합이 발생한 것이다.   
> 훈련셋 성능은 rmse가 낮고 검증셋의 성능은 훈련셋의 성능과 어느정도 차이가 벌어진다.   
> 해결을 위해서 **훈련셋의 성능과 검증셋의 성능이 맞닿을 때까지 훈련데이터를 추가**하거나 **모델에 규제를 가한다**. 

16. __테스트셋이 무엇이며 왜 사용하길 원하는가__
> 테스트셋이란 실전에 배치되기 전 모델이 새로운 샘플에 대해 만들 일반화오차를 추정하기 위해 사용.

17. __검증셋의 목적은 무엇인가__
> 모델을 비교하는데 사용된다. 이를 통해 가장 좋은 모델을 고르며 하이퍼파라미터를 튜닝한다

18. __훈련-개발 세트가 무엇인가? 언제 필요하며 어떻게 사용해야 하는가__
> 검증, 테스트셋에 사용되어야하는 데이터와 훈련셋 사이에 데이터 불일치 위험이 있을 때 사용   
> 훈련셋의 일부에서 모델을 훈련하고 훈련-개발셋과 검증셋에서 평가

19. __테스트셋를 사용해 하이퍼파라미터를 튜닝하면 어떤 문제가 생기는가?__
> 테스트셋에 과대적합될 위험이 있고 일반화 오차를 낙관적으로 측정하게 된다.


---

# Chap4.
1. __수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까?__
> 확률적 경사하강법이나 미니배치 경사하강법을 사용할 수 있다.   
> 훈련세트가 메모리 크기에 맞으면 배치경사하강법도 사용할 수 있다.   

    <확률적 경사하강법(SGD)>
    - 배치크기 = 1, 스텝크기=데이터크기
    - 큰 훈련세트 다를 수 있음. 외부 메모리 학습 활용 가능
    - 파라미터 조정이 불안정하게 이뤄질 수 있어 지역최솟값에 덜 민감하지만 같은 이유로 전역최솟값에 수렴하지 못할 수 있음
    
    
    <미니배치경사하강법>   
    - 배치크기=2~수백(사용자 지정)
    - SGD보다 파라미터 움직임이 덜 규칙적이다. 배치경사하강법보다 빠른 학습
    - SGD보다 지역최솟값에 수렴할 위험도 증가
    
    
    <배치경사하강법>   
    - 배치크기 = 데이터크기, 스텝크기 = 1
    
    
    배치GD-미니배치GD-SGD 순으로 최적의 파라미터 값에 수렴할 확률 높아지며 훈련시간 오래걸림

2. __훈련 세트에 있는 특성들이 각기 아주 다른 스케일을 가지고 있다. 이런 데이터에 잘 작동하지 않는 알고리즘은 무엇일까? 그 이유? 이 문제를 어떻게 해결할 수 있을까?__
> 경사하강법. 비용함수가 길쭉한 타원모양이 되기 때문이다.   
> 해결: 모델 훈련 전 스케일링을 통해 모든 테이터 특성의 척도를 통일한다.

3. __경사 하강법으로 로지스틱 회귀 모델을 훈련 시킬 때 지역 최솟값에 갇힐 가능성이 있을까?__
> 로지스틱 회귀모델의 비용함수는 볼록함수이므로 가능성이 없다

4. __충분히 오랫동안 실행하면 모든 경사 하강법 알고리즘이 같은 모델을 만들어낼까?__
> 최적화할 함수가 볼록함수이고 학습률이 너무 크지 않다고 가정하면 모든 경사하강법 알고리즘이 전역최솟값에 도달하고 비슷한 모델을 만들겠지만   
> 학습률을 점진적으로 감소시키지 않는다면 SGD와 미니배치GD는 진정한 최적점에 수렴하지 못할 것이고 전역 최적점 주변을 맴돌게 된다.   
> 즉 매우 오랫동안 훈련을 해도 경사하강법 알고리즘은 조금씩 다른 모델을 만든다

5. __배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤다. 만약 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 것인가? 이 문제를 어떻게 해결 할 수 있을까?__
> 학습률이 높고 알고리즘이 발산하는 것일지 모른다.   
> 훈련에러가 올라간다면 위 문제이고 학습률을 낮춰야하지만   
> 훈련에러가 올라가지 않으면 과대적합되는 것이므로 훈련을 조기종료해야한다.

6. __검증 오차가 상승하면 미니배치 경사 하강법을 즉시 중단하는 것이 좋은 방법인가__
> 지역 최솟값일수도 있으므로 더 나은 방법은 정지적으로 모델을 저장하고 최상의 검증점수를 넘어가지 못할 때 종료해 저장된 것 중 가장 좋은 모델로 복원하는 것이다.

7. __어떤 경사 하강법 알고리즘이 가장 빠르게 최적 솔루션의 주변에 도달할 수 있을까? 실제로 수렴하는 것은 어떤 것인가? 다른 방법들도 수렴하게 만들 수 있을까?__
> 배치크기가 가장 작은 SGD가 가장 먼저 솔루션 주변에 도달한다. 그 다음은 미니배치GD이다.    
> 시간이 충분하다면 배치GD만 수렴할 것이다. 학습률을 점진적으로 감소시키지 않으면 SGD와 미니배치GD는 전역최솟값 주변을 맴돌 것이다.   

8. __다항 회귀를 사용했을 때 학습 곡선을 보니 훈련 오차와 검증 오차 사이에 간격이 크다. 무슨 일이 생긴 걸까? 이 문제를 해결하는 세 가지 방법은 무엇인가?__
> 과대적합이 발생하였다.   
> 다항 차수를 낮추거나 두 오차가 줄어들 때까지 훈련데이터를 추가하거나 모델에 규제를 가한다.   

9. __릿지 회귀를 사용했을 때 훈련 오차와 검증 오차가 거의 비슷하고 둘 다 높았다. 이 모델에는 높은 편향과 높은 분산 중 어느 것이 문제인가? 규제 하이퍼파라미터  α 를 증가시켜야 할까, 아니면 줄여야 할까?__
> 과소적합이 발생했으므로 높은 편향이 문제이다.   
> 알파를 증가시키면 데이터에 덜 민감해지므로 감소시켜야한다.

10. __다음과 같이 사용해야 하는 이유는?__
- 평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀
- 릿지 회귀 대신 라쏘 회귀
- 라쏘 회귀 대신 엘라스틱넷
> 릿지회귀는 일반적으로 추천된다. 규제가 있는 모델이 없는 모델보다 성능이 좋기 때문   
> 유용하지 않은 특성이 많이 포함되어있는 데이터로 훈련할 때 라쏘회귀가 추천된다.   
> 특성 수가 훈련샘플 수보다 크거나 특정 특성이 강하게 연관되어있을 경우   

11. __사진을 낮과 밤, 실내와 실외로 분류하려고 한다. 두 개의 로지스틱 회귀 분류기를 만들어야 할까, 하나의 소프트맥스 회귀 분류기를 만들어야 할까?__
> 네가지 조합이 모두 가능하므로 두개의 로지스틱 회귀 분류기가 좋다.

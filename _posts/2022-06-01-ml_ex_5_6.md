---
title: '[Blog]핸즈온머신러닝 3판 5장, 6장 연습문제'
layout: single
categories:
  - Study
tag:
  - Blog
  - machinelearning
---
# Chap5.

## 1.
> __Support Vector Machine 의 기본 아이디어는 무엇인가?__
- 클래스 사이에 최대한 넓은 결정경계도로를 내는 것이다.  
클래스를 구분하는 결정경계와 샘플사이의 마진을 최대화하는 것이다.

## 2. 
> __서포트벡터란 무엇인가__
- 결정경계 도로의 가장자리에 있는 점이다.

## 3.
> __SVM에서 입력의 스케일이 왜 중요한가?__
- 특성의 스케일 차이가 많이 나는 경우보다 표준화된 특성을 사용할 때 더 좋은 결정경계(넓은 마진)가 나온다

## 4. 
> __SVM분류기가 샘플을 분류할 때 신뢰도 점수와 확률을 출력할 수 있는가?__
- 테스트 샘플과 결정경계 사이의 거리를 신뢰도 점수로 사용할 수 있고 확률 예측 메서드로 확률을 계산할 수 있다.

## 5.
> __수백만개의 인스턴스와 수백개의 특성이 있는 훈련셋에서 모델을 훈련하기위해 SVM의 원문제와 쌍대문제 중 어떤 것을 사용해야할까?__
- 데이터와 특성의 양이 많으므로 쌍대문제가 아니라 원문제를 사용해야한다.

## 6. 
> __RBF커널을 통해 SVM분류기를 훈련시켰더니 훈련셋에서 과소적합되었다. γ를 증가시켜야할까 감소시켜야할까? 규제C는 어떻게해야하나__
- γ와규제 C를 증가해야한다.   
γ는 증가할수록 샘플의 영향력이 작은 영역으로 줄어들고 C는 증가시킬수록 규제의 강도가 낮아진다.


# 6장

## 1.
> __규제없이 백만개의 샘플을 가진 훈련셋에서 훈련시킨 결정트리의 깊이는 대략 얼마인가__
- log<sub>2</sub>(m)이므로 log<sub>2</sub>(10<sup>6</sup>) = 20

## 2. 
> __한노드의 지니불순도가 보통 그 부모보다 작을까 클까? 일반적으로 작거나 클까 아니면 항상 작거나 클까?__
- 일반적으로 작다.  
지니불순도를 최소화하는 것을 목표로 CART알고리즘이 탐욕기법을 사용하기 때문이다.
- 부모노드에 A클래스 4개, B클래스 1개가 있으면 지니불순도는 1 - (1/5)<sup>2</sup> − (4/5)<sup>2</sup> = 0.32.  
자식노드가 A,B가진 노드와 A 3개 가진 노드로 분류되었다고 가정하면 A,B클래스를 가진 노드의 지니불순도는 1 - (1/2)<sup>2</sup> − (1/2)<sup>2</sup> = 0.5.  

## 3.
> __결정트리가 훈련셋에 과대적합되었다면 `max_depth`를 줄이는 것이 좋을까?__
- 줄이는 것이 좋다. 과대적합일 때는 규제를 높여야하고 `max_depth`는 규제를 줄이기위해 크기를 줄이면 된다.

## 4. 
> __결정트리가 훈련셋에 과소적합되었다면 입력 특성의 스케일을 조정한느 것이 좋을까?__
- 결정트리는 훈련셋의 스케일과 상관이 없다는 것이 장점 중 하나이다. 따라서 스케일 조정은 관련이 없다.

## 5.
> __백만개의 샘플을 가진 훈련셋에 결정트리를 훈련시키는데 한시간이 걸렸다.  
> 천만개의 샘플을 가진 훈련셋에 결정트리를 훈련시킬때는 대략 얼마나 시간이 걸릴까?__
- 결정트리의 시간복잡도는 `O(n×mlog(m))`이다.  
훈련셋 크기에 10을 곱한 것이므로 (n × 10m × log(10m))/(n × m × log(m)) = 10 × log(10m)/log(m)이고  m=10<sup>6</sup>이므로 약 11.7시간 정도이다.

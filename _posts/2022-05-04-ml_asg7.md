---
title: '[Blog]분류에 대한 정리'
layout: post
categories:
  - Python
tag:
  - Blog
  - machinelearning
  - assignment
toc: true
toc_label: "on this page"
toc_sticky: true
published : true
---

[Getting started with classification ](https://github.com/codingalzi/ML-For-Beginners/tree/main/4-Classification/1-Introduction) 내용에 대한 학습과 정리에 대한 내용입니다.

# 분류 소개

앞으로 소개할 4개의 강의에서는 머신러닝의 기본 초점, **분류**를 탐구할 것이다.

우리는 아시아와 인도의 모든 훈륭한 요리에 대한 데이터셋을 사용해 다양한 분류 알고리즘을 사용해 안내할 것이다.

_Hope you're hungry!_


**분류란?**

회귀 기술과 많은 공통점이 있는 지도학습의 한 형태이다(지도학습은 크게 회귀와 분류로 나눌 수 있음).

머신러닝이 데이터셋을 이용해 사물에 대한 값이나 이름을 예측하는 것이라면 분류는 이진 분류와 다중 클래스 분류로 나눌 수 있다.

[분류 소개 _MIT's John Guttag](https://www.youtube.com/watch?v=eg8DJYwdMyg)

**기억해야할 것**
- 선형회귀는 변수간 관계를 예측하고 새 데이터가 해당 선과 관련된 위치에 대해 정확하게 예측하는 것을 돕는다. (예를 들면 9원과 12월의 호박가격을 예측하는 것)
- 로지스틱 회귀는 `이진범주`를 발견하는데 도움이 된다. (어떤 가격대에서 이 호박이 주황색인지 아닌지와 같은 것 예측)

__분류__ 는 다양한 알고리즘을 사용해 데이터 포인트의 레이블 또는 클래스를 결정하는 다른 방법을 결정한다.

이 요리 데이터를 사용해 재료 그룹을 관찰해 원산지 요리를 결정할 수 있는지 알아보자.

## 소개

분류는 머신러닝연구원과 데이터 과학자의 기본 활동 중 하나이다.

이진 값의 기본 분류(스팸 메일인지 아닌지)에서 컴퓨터의 비전을 사용한 복잡한 이미지 분류 및 세분화에 이르기까지 데이터를 클래스로 분류하고 질문할 수 있는 것은 항상 유용하다.

보다 과학적인 방식으로 프로세스를 설명하기 위해 분류방법은 입력변수 간의 관계를 출력 변수에 매핑할 수 있는 예측 모델을 생성한다.

데이터 정리, 시각화, ML작업 준비 과정을 시작하기 전에 머신러닝을 활용한 데이터분류의 다양한 방법에 대해 알아보자.

통계에서 파생된 고전적인 머신러닝을 사용한 분류는 `흡연자`, `체중`, `연령`과 같은 기능을 사용해 X질병이 발병될 가능성을 결정한다.

회귀연급과 유사한 지도학습 기술로 데이터에 레이블이 지정되고, ML알고리즘은 해당 레이블을 사용해 데이터셋의 클래스(특성)를 분류/예측하고 그룹이나 결과에 할당하게 된다.

✅ 요리에 대한 데이터셋을 상상해봐라. 

- 다중 클래스 모델은 무엇에 답할 수 있을까?
- 이진 모델은 무엇에 답할 수 있을까?
- 요리에 호로파(fenugreek)을 사용할 가능성이 있는지 확인하기 위해서 어떻게 해야할까?
- 스타 아니스(star anise), 아티초크(artichokes), 콜리플라워(cauliflower),와사비(horseradish)로 가득 찬 식료풍 가방을 선물로 주어 전형적인 인도 요리를 만들 수 있는 가를 알고싶다면 어떻게 해야할까?



## 분류

이 요리 데이터셋에 대해 묻고싶은 질문은 실제로 여러 잠재적인 국가의 요리를 만들 수 있기 때문에 다중 클래스 질문에 해당할 것이다.

재료 배치가 주어지면 많은 클래스 중 데이터가 맞는 것은 무엇일까?

---

Scikit-learn은 해결하려는 문제의 종류에 따라 데이터를 분류하는데 사용할 여러 알고리즘을 제공한다.

다음에 소개할 두 강의에서는 이러한 알고리즘 중 몇 가지에 대해 배울 것이다.

## 연습문제 - 데이터 정리와 균형 맞추기

항상 프로젝트를 시작하기 전 가장 먼저 해야할 일은 데이터를 정리하고 균형을 맞추는 것이다. 이는 우리가 더 나은 결과를 얻을 수 있도록 도와준다.

****

imblearn은 데이터의 균형을 더 잘 맞출 수 있도록 해주는 Scikit-learn 패키지이다.


```python
# imblearn을 설치할 수 있다.
pip install imblearn
```

    Collecting imblearn
      Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)
    Collecting imbalanced-learn
      Downloading imbalanced_learn-0.9.0-py3-none-any.whl (199 kB)
    Requirement already satisfied: scipy>=1.1.0 in c:\users\pc\anaconda3\lib\site-packages (from imbalanced-learn->imblearn) (1.7.1)
    Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\pc\anaconda3\lib\site-packages (from imbalanced-learn->imblearn) (2.2.0)
    Collecting scikit-learn>=1.0.1
      Downloading scikit_learn-1.0.2-cp39-cp39-win_amd64.whl (7.2 MB)
    Requirement already satisfied: joblib>=0.11 in c:\users\pc\anaconda3\lib\site-packages (from imbalanced-learn->imblearn) (1.1.0)
    Requirement already satisfied: numpy>=1.14.6 in c:\users\pc\anaconda3\lib\site-packages (from imbalanced-learn->imblearn) (1.20.3)
    Installing collected packages: scikit-learn, imbalanced-learn, imblearn
      Attempting uninstall: scikit-learn
        Found existing installation: scikit-learn 0.24.2
        Uninstalling scikit-learn-0.24.2:
          Successfully uninstalled scikit-learn-0.24.2
    Successfully installed imbalanced-learn-0.9.0 imblearn-0.0 scikit-learn-1.0.2
    Note: you may need to restart the kernel to use updated packages.
    


```python
# 데이터를 표시하고 시각화하는데 필요한 패키지를 import한다.
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import numpy as np

# imblearn에서 SMOTE도 불러온다
from imblearn.over_sampling import SMOTE
```


```python
# 이제 필요한 데이터를 불러온다.
# read_csv()를 사용해 csv파일의 내용을 불러오고 데이터프레임으로 만들었다.
df  = pd.read_csv('cuisines.csv')
```


```python
# 데이터의 형태를 살펴보기 위해 맨 앞 데이터 5개를 불러온다.
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>cuisine</th>
      <th>almond</th>
      <th>angelica</th>
      <th>anise</th>
      <th>anise_seed</th>
      <th>apple</th>
      <th>apple_brandy</th>
      <th>apricot</th>
      <th>armagnac</th>
      <th>...</th>
      <th>whiskey</th>
      <th>white_bread</th>
      <th>white_wine</th>
      <th>whole_grain_wheat_flour</th>
      <th>wine</th>
      <th>wood</th>
      <th>yam</th>
      <th>yeast</th>
      <th>yogurt</th>
      <th>zucchini</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>65</td>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>66</td>
      <td>indian</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>67</td>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>68</td>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>69</td>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 385 columns</p>
</div>




```python
# info()를 사용하면 데이터에 대한 정보가 요약되어 나온다.
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 2448 entries, 0 to 2447
    Columns: 385 entries, Unnamed: 0 to zucchini
    dtypes: int64(384), object(1)
    memory usage: 7.2+ MB
    

### 요리에 대해 배우자!(데이터에 대한 정보)

이제 작업이 더 흥미로워질 것이다.
요리별 데이터의 분포를 알아보자.


```python
df.cuisine.value_counts().plot.barh()
```




    <AxesSubplot:>




    
![사진](/assets/img/output_21_1.png)
    


요리의 수는 유한한지만 데이터의 분포는 고르지 않다는 것을 확인할 수 있다.

이를 고쳐보자. 하지만 그 전에 조금 더 탐색할 것.


```python
# 요리 별로 사용할 수 있는 데이터의 양을 확인 후 출력하자
thai_df = df[(df.cuisine == "thai")]
japanese_df = df[(df.cuisine == "japanese")]
chinese_df = df[(df.cuisine == "chinese")]
indian_df = df[(df.cuisine == "indian")]
korean_df = df[(df.cuisine == "korean")]

print(f'thai df: {thai_df.shape}')
print(f'japanese df: {japanese_df.shape}')
print(f'chinese df: {chinese_df.shape}')
print(f'indian df: {indian_df.shape}')
print(f'korean df: {korean_df.shape}')
```

    thai df: (289, 385)
    japanese df: (320, 385)
    chinese df: (442, 385)
    indian df: (598, 385)
    korean df: (799, 385)
    

### 재료 찾기

데이터를 더 자세히 살펴보고 요리별로 일반적인 재료가 무엇인지 알아보자.

반복되는 데이터는 요리 간에 혼동을 줄 것이다. 우리는 이를 정리해야한다.

`create_ingredient()`함수를 만들어 재료 데이터 프레임을 만들 것이다. 이 기능은 도움이 되지 않는 열을 삭제하고 개수를 기준으로 재료를 정렬한다.


```python
# 우리는 아래의 함수로 요리별로 가장 인기있는 상위 10개의 재료를 알 수 있다
def create_ingredient_df(df):
    ingredient_df = df.T.drop(['cuisine','Unnamed: 0']).sum(axis=1).to_frame('value')
    ingredient_df = ingredient_df[(ingredient_df.T != 0).any()]
    ingredient_df = ingredient_df.sort_values(by='value', ascending=False,
    inplace=False)
    return ingredient_df
```

태국 음식에 대해 `barh()`로 나타내기


```python
thai_ingredient_df = create_ingredient_df(thai_df)
thai_ingredient_df.head(10).plot.barh()
```




    <AxesSubplot:>




    
![pic2](/assets/img/output_28_1.png)
    


일본 음식에 대해 `barh()` 로 나타내기


```python
japanese_ingredient_df = create_ingredient_df(japanese_df)
japanese_ingredient_df.head(10).plot.barh()
```




    <AxesSubplot:>




    
![png3](/assets/img/output_30_1.png)
    


한국 음식에 대해 `barh()` 로 나타내기


```python
korean_ingredient_df = create_ingredient_df(korean_df)
korean_ingredient_df.head(10).plot.barh()
```




    <AxesSubplot:>




    
![png4](/assets/img/output_32_1.png)
    


이제 `drop()`을 사용해 고유한 요리 간 혼동을 일으키는 가장 일반적인 재료를 삭제할 것이다.

위 자료 이외에 다른 여러 나라의 음식을 확인해보면 보통 쌀, 마늘, 생강은 대부분 재료로 들어가있다.


```python
# 쌀, 마늘, 생강 drop
feature_df= df.drop(['cuisine','Unnamed: 0','rice','garlic','ginger'], axis=1)
labels_df = df.cuisine #.unique()
feature_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>almond</th>
      <th>angelica</th>
      <th>anise</th>
      <th>anise_seed</th>
      <th>apple</th>
      <th>apple_brandy</th>
      <th>apricot</th>
      <th>armagnac</th>
      <th>artemisia</th>
      <th>artichoke</th>
      <th>...</th>
      <th>whiskey</th>
      <th>white_bread</th>
      <th>white_wine</th>
      <th>whole_grain_wheat_flour</th>
      <th>wine</th>
      <th>wood</th>
      <th>yam</th>
      <th>yeast</th>
      <th>yogurt</th>
      <th>zucchini</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 380 columns</p>
</div>



### 데이터셋 균형 맞추기

SMOTE("Synthetic Minority Over-sampling Technique")를 사용해 균형을 맞추자.

`fit_resample()`을 호출한다. 이는 보간법으로 새 샘플을 생성한다.


```python
oversample = SMOTE()
transformed_feature_df, transformed_label_df = oversample.fit_resample(feature_df, labels_df)
```

데이터 균형을 맞춤으로 우린 분류에서 더 좋은 결과를 얻을 것이다.

이진 분류를 생각해보자.
만약 우리의 데이터가 한 클래스라면 해당 클래스에 대한 데이터가 더 많기 때문에 머신러닝 모델은 더 자주 클래스를 예측할 것이다.

데이터 균형을 맞추면 왜곡된 데이터를 가져와 이런 불균형을 제거하는 데에 도움이 된다.


```python
# 재료당 라벨의 개수를 확인한다.
print(f'new label count: {transformed_label_df.value_counts()}')
print(f'old label count: {df.cuisine.value_counts()}')
```

    new label count: indian      799
    thai        799
    chinese     799
    japanese    799
    korean      799
    Name: cuisine, dtype: int64
    old label count: korean      799
    indian      598
    chinese     442
    japanese    320
    thai        289
    Name: cuisine, dtype: int64
    

위 데이터를 보면 잘 정리되어있다.

마지막 단계는 레이블 및 기능을 포함해 균형잡힌 데이터를 파일로 내보낼 수 있는 새로운 데이터 프레임에 저장하는 것이다.


```python
transformed_df = pd.concat([transformed_label_df,transformed_feature_df],axis=1, join='outer')
```

`transformed_df.head()`와 `transformed_df.info()`를 사용해 데이터를 한번에 볼 수 있다.


```python
transformed_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cuisine</th>
      <th>almond</th>
      <th>angelica</th>
      <th>anise</th>
      <th>anise_seed</th>
      <th>apple</th>
      <th>apple_brandy</th>
      <th>apricot</th>
      <th>armagnac</th>
      <th>artemisia</th>
      <th>...</th>
      <th>whiskey</th>
      <th>white_bread</th>
      <th>white_wine</th>
      <th>whole_grain_wheat_flour</th>
      <th>wine</th>
      <th>wood</th>
      <th>yam</th>
      <th>yeast</th>
      <th>yogurt</th>
      <th>zucchini</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>indian</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 381 columns</p>
</div>




```python
transformed_df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 3995 entries, 0 to 3994
    Columns: 381 entries, cuisine to zucchini
    dtypes: int64(380), object(1)
    memory usage: 11.6+ MB
    


```python
transformed_df.to_csv("cleaned_cuisines.csv")
```

## 고민해볼 것

이진/다중 클래스 분류에 적합한 데이터를 보며 우리는 그 데이터셋에 대해 어떤 질문을 던질 수 있을지 고민해보자.

# 요리 분류기1

위에서 정리된 데이터로 분류기를 사용해 재료 그룹을 기반으로 주어진 국가의 요리를 예측한다.

그러는 동안 분류 작업에 알고리즘을 활용할 수 있는 몇가지 방법에 대해 자세히 알아볼 것이다.

## 연습문제 - 국가의 요리를 예측하자.


```python
# 판다스 라이브러리 import
import pandas as pd

# 위에서 저장한 정리된 데이터셋 불러오기
cuisines_df = pd.read_csv("cleaned_cuisines.csv")
cuisines_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>cuisine</th>
      <th>almond</th>
      <th>angelica</th>
      <th>anise</th>
      <th>anise_seed</th>
      <th>apple</th>
      <th>apple_brandy</th>
      <th>apricot</th>
      <th>armagnac</th>
      <th>...</th>
      <th>whiskey</th>
      <th>white_bread</th>
      <th>white_wine</th>
      <th>whole_grain_wheat_flour</th>
      <th>wine</th>
      <th>wood</th>
      <th>yam</th>
      <th>yeast</th>
      <th>yogurt</th>
      <th>zucchini</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>indian</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 382 columns</p>
</div>




```python
# 필요한 라이브러리 더 import
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
from sklearn.svm import SVC
import numpy as np
```

훈련을 위해 데이터셋을 X,y의 두 개의 데이터 프레임으로 나눈다.

요리는 레이블 데이터 프레임이 될 수 있다.


```python
cuisines_label_df = cuisines_df['cuisine']
cuisines_label_df.head()
```




    0    indian
    1    indian
    2    indian
    3    indian
    4    indian
    Name: cuisine, dtype: object



이름 없는 0번열과 요리 열을 `drop()`을 사용해 버린다.

나머지 데이터를 학습가능한 형태로 저장한다.


```python
cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)
cuisines_feature_df.head()

# 이를 통해 우린 모델 훈련 준비가 끝났다.
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>almond</th>
      <th>angelica</th>
      <th>anise</th>
      <th>anise_seed</th>
      <th>apple</th>
      <th>apple_brandy</th>
      <th>apricot</th>
      <th>armagnac</th>
      <th>artemisia</th>
      <th>artichoke</th>
      <th>...</th>
      <th>whiskey</th>
      <th>white_bread</th>
      <th>white_wine</th>
      <th>whole_grain_wheat_flour</th>
      <th>wine</th>
      <th>wood</th>
      <th>yam</th>
      <th>yeast</th>
      <th>yogurt</th>
      <th>zucchini</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 380 columns</p>
</div>



### 분류기 고르기

이제 데이터가 정리되고 학습할 준비가 되었으므로 작업에 사용할 알고리즘을 결정해야한다.

`Scikit-learn`은 지도학습에서 분류를 그룹화하고 해당 범주에서 분류하는 다양한 방법을 찾을 수 있다.

다양성한 것은 처음에는 꽤 어렵게 느껴진다. 아래는 분류 기술을 나열하였다.

- Linear Models
- Support Vector Machines
- Stochastic Gradient Descent
- Nearest Neighbors
- Gaussian Processes
- Decision Trees
- Ensemble methods (voting Classifier)
- Multiclass and multioutput algorithms (multiclass and multilabel classification, multiclass-multioutput classification)

#### 어떤 분류기를 사용할 것인가?

테스트하는 방법은 여러가지를 실행 후 좋은 결과를 찾는 것이다.

`Scikit-learn`은 `KNeighbors`, `SVC`의 두 가지 방식을 제공한다.

아래는 (GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB 및 QuadraticDiscrinationAnalysis)로 비교해 생성된 데이터세트에 대한 병렬비교를 제공해 시각화된 결과를 보여준다.



![png5](/assets/img/mlasg7_img1.png)
    


#### 더 좋은 접근

성급하게 추측하는 것보다 더 좋은 방법은 다운로드가 가능한 머신러닝 치트시트의 아이디어를 따르는 것이다.
여기서 우린 다중 클래스 문제에 대해 몇가지 선택사항이 있음을 발견한다.




![png6](/assets/img/mlasg7_img2.png)
    


#### Reasoning

가지고 있는 제약조건을 감안할 때 다른 접근 방식을 통해 추론이 가능한지 살펴보자.

- __신경망(Neural networks)은 너무 무겁다.__ 깨끗하지만 최소한의 데이터셋과 노트북을 통해 초컬로 훈련을 실행하고 있다는 사실을 감안할 때 신경망은 이 작업에 너무 무겁다.
- __2-클래스 분류기가 없다.__ 우리는 일대일(OV)을 배제하기 위해 2-클래스 분류기를 사용하지 않는다. 
- __결정트리 또는 로지스틱 회귀가 작동할 수 있다.__ 결정트리가 작동하거나 다중 클래스 데이터에 대한 로지스틱 회귀가 작동할 수 있다.
- __다중클래스 부스트 결정 트리는 다른 문제를 해결한다.__ 다중클래스 부스트 결정트리는 비모수적 작업에 가장 적합하다. 순위를 만들기 위해 설계된 작업이므로 우리에겐 유용하지 않다.

#### Scikit-learn 사용하기

우리는 Scikit-learn을 사용해 데이터를 분석할 것이다.

하지만 Scikit-learn에서 로지스틱 회귀를 사용하는 방법은 여러가지가 있다. 전달할 파라미터를 살펴봐라.

본질적으로 우리가 Scikit-learn에 로지스틱 회귀를 수행하도록 요청할 때 지정해야한느 두 가지 중요 파라미터인 `multi_class`와 `solver`가 있다. `multi_class`값은 특정 동작을적용한다. `solver`의 값은 사용할 알고리즘이다. 모든 `solver`와 `multi_class`가 짝을 이룰 수있는 것은 아니다.

문서에 따르면 다중 클래스의 경우 학습알고리즘은 다음과 같다.
- `multi_class`옵션이 `ovr`로 설정된 경우 one-vs-rest(OvR)체계를 사용한다.
- `multi_class`옵션이 `multinomial`로 설정된 경우 (현재 `multinomial`옵션은 ‘lbfgs’, ‘sag’, ‘saga’,‘newton-cg’ slover에서만 지원된다.)

🎓 여기서 `scheme`는 `ovr`또는 `multinomial`이 될 수 있다. 

로지스틱 회귀는 실제로 이진 분류를 지원하도록 설계되어있으므로 이러한 체계를 사용하면 다중 클래스 분류 작업을 더 잘 처리할 수 있다.

🎓 `solver`는 최적화 문제에 사용할 알고리즘으로 정의된다.

`Scikit-learn`은 `solver`가 다양한 종류의 데이터 구조가 제시하는 다양한 문제를 처리하는 방법을 설명하기 위해 다음 표를 제공한다.


![png5](/assets/img/mlasg7_img3.png)
    


### 데이터 나누기


```python
# train_test_split()을 사용하면 쉽게 데이터를 훈련/테스트 셋으로 분할할 수 있다.
X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
```

### 로지스틱 회귀 적용하기

다중 클래스 사례를 사용하기때문에, 사용할 `scheme`와 `solver`를 선택해야한다.

훈련할 다중 클래스 세팅과 `liblinear solver`, `LogisticRegression`을 사용한다.


```python
# milto_class의 옵션을 ovr로 설정하고 solver의 옵션을 liblinear로 설정해 로지스틱 회귀 생성
lr = LogisticRegression(multi_class='ovr',solver='liblinear')
model = lr.fit(X_train, np.ravel(y_train))

accuracy = model.score(X_test, y_test)
print ("Accuracy is {}".format(accuracy))

# 정확도가 거의 80%가 나온다.
```

    Accuracy is 0.79232693911593
    

✅ 종종 기본값으로 설정되는 `lbfgs`와 같은 다른 `solver`를 사용해볼 수도 있다.

한 행에 데이터를 테스트하면 이 모델이 작동한는 것을 확인할 수 있다.


```python
# 50번째 행
print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')
print(f'cuisine: {y_test.iloc[50]}')
```

    ingredients: Index(['coconut'], dtype='object')
    cuisine: thai
    

더 깊이 파고들면 이 예측의 정확성을 확인할 수도 있다.


```python
test= X_test.iloc[50].values.reshape(-1, 1).T
proba = model.predict_proba(test)
classes = model.classes_
resultdf = pd.DataFrame(data=proba, columns=classes)

topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])
topPrediction.head()
```

    C:\Users\pc\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
      warnings.warn(
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>thai</th>
      <td>0.793984</td>
    </tr>
    <tr>
      <th>chinese</th>
      <td>0.071358</td>
    </tr>
    <tr>
      <th>japanese</th>
      <td>0.063747</td>
    </tr>
    <tr>
      <th>indian</th>
      <td>0.043105</td>
    </tr>
    <tr>
      <th>korean</th>
      <td>0.027805</td>
    </tr>
  </tbody>
</table>
</div>



분류 보고서를 인쇄해 더 자세한 정보를 얻어보자.


```python
y_pred = model.predict(X_test)
print(classification_report(y_test,y_pred))
```

                  precision    recall  f1-score   support
    
         chinese       0.72      0.69      0.71       230
          indian       0.91      0.91      0.91       250
        japanese       0.76      0.76      0.76       245
          korean       0.84      0.75      0.79       249
            thai       0.73      0.85      0.78       225
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    
    

## 고민해볼 것

`Scikit-learn`이 데이터 분류를 위해 제공하는 다양한 옵션을 살펴보자. 그 안에서 무슨 일이 이해하셔면 `solver`의 개념을 더 자세히 공부하면 된다.

# 요리 분류기2

위에서 우린 Microsoft의 치트 시트를 사용하여 데이터를 분류할 때 사용할 수 있는 다양한 옵션에 대해 배웠다.

Scikit-learn은 추정기(분류기)를 좁히는 데 도움이 될 수 있는 유사하지만 더 세분화된 치트 시트를 제공한다.


![png8](/assets/img/mlasg7_img4.png)
    


위 맵은 데이터를 명확하게 파악하고 나면 결정에 이르는 경로를 따라갈 수 있으므로 매우 유용하다.

_예시_
- 50개의 샘플
- 범주를 예측하고싶음
- 라벨링된 데이터가 있음
- 약 100,000개의 샘플이 있음
- 우린 `Linear SVC`를 선택할 수 있음
- 만약 데이터의 수로 인해 작동하지 않는다면,
    - `KNeighbors Classifier`를 시도할 수 잇음
        - 만약 이도 작동하지 않는다면, `SVC`와 `Ensemble 분류기`를 사용할 수 있음

#### 데이터 나누기


```python
# 필요 라이브러리 import
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
import numpy as np
```


```python
# 데이터 나누기
X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
```

### Linear SVC 분류기

SVC(Support-Vector clustering)은 서포트벡터머신의 하위 항목이다.

이는 `kernel`을 선택해 레이블을 군집화하는 방법을 결정할 수 있다.

`C`파라미터는 파라미터의 영향을 규제하는 정규화를 나타낸다.

`kernel`은 여러개 중 하나일 수 있다. 여기서 Linear SVC를 활용하도록 `linear`로 설정한다. probability는 기본적으로 `false`이다. 하지만 여기선 확률 추정치를 수집하기 위해 `true`로 설정한다. 확률을 얻기 위해 데이터를 섞고자 ramdom_state는 `0`으로 설정한다.


```python
C = 10
# 다른 분류기들 만들기
classifiers = {
    'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
}
```


```python
# 만든 모델을 훈련해보고 보고서를 출력해보자.
n_classifiers = len(classifiers)

for index, (name, classifier) in enumerate(classifiers.items()):
    classifier.fit(X_train, np.ravel(y_train))

    y_pred = classifier.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
    print(classification_report(y_test,y_pred))
```

    Accuracy (train) for Linear SVC: 76.0% 
                  precision    recall  f1-score   support
    
         chinese       0.66      0.66      0.66       248
          indian       0.89      0.87      0.88       233
        japanese       0.75      0.70      0.73       249
          korean       0.75      0.78      0.76       237
            thai       0.76      0.80      0.78       232
    
        accuracy                           0.76      1199
       macro avg       0.76      0.76      0.76      1199
    weighted avg       0.76      0.76      0.76      1199
    
    

### [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors) 분류기(K-최근접 이웃, KNN)

K-Neighbors 는 지도/비지도 학습 모두에 사용할 수 이쓴ㄴ 머신러닝방법의 `neighbor`계열의 일부이다. 

이 방법에서 미리 정의된 수의 포인트가 생성되고 데이터에 대해 일반화된 레이블을 예측할 수 있도록 주변 데이터를 수집한다.

K-Neighbors분류기를 통해 우린 더 좋은 성능을 얻을지도 모른다.


```python
# 분류기 배열에 줄을 추가한다.
# 성능이 좋지 않다.
'KNN classifier': KNeighborsClassifier(C),
```


```python
Accuracy (train) for KNN classifier: 73.8% 
              precision    recall  f1-score   support

     chinese       0.64      0.67      0.66       242
      indian       0.86      0.78      0.82       234
    japanese       0.66      0.83      0.74       254
      korean       0.94      0.58      0.72       242
        thai       0.71      0.82      0.76       227

    accuracy                           0.74      1199
   macro avg       0.76      0.74      0.74      1199
weighted avg       0.76      0.74      0.74      1199
```

### [Support Vector](https://scikit-learn.org/stable/modules/svm.html#svm) 분류기(SVC)

서포트벡터머신의 일부이다.

두 범주 간의 거리를 최대화하기 위해 __공간의 지점에 훈련 예제를 매핑__ 한다. 후속 데이터는 해당 범주를 예측할 수있도록 이 공한에 매핑된다.


```python
# 분류기 배열에 줄을 추가한다.
# 성능이 꽤 좋아졌다는 것을 확인할 수 있다.
'SVC': SVC(),
```


```python
Accuracy (train) for SVC: 83.2% 
              precision    recall  f1-score   support

     chinese       0.79      0.74      0.76       242
      indian       0.88      0.90      0.89       234
    japanese       0.87      0.81      0.84       254
      korean       0.91      0.82      0.86       242
        thai       0.74      0.90      0.81       227

    accuracy                           0.83      1199
   macro avg       0.84      0.83      0.83      1199
weighted avg       0.84      0.83      0.83      1199
```

### [Ensemble](https://scikit-learn.org/stable/modules/ensemble.html)분류기

Ensemble 분류기, 특히 Random Forest 및 AdaBoost를 사용해보자.
- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest) : 결정트리를 여러개 사용(`n_eatimators`파라미터로 훈련 결정트리의 수 결정
- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) : 분류기를 데이터셋에 맞추고 분류기의 복사본을 동일 데이터셋에 맞춤. 잘못 분류된 항복의 가중치에 초점을 맞추고 다음 분류기가 수정하도록 맞춤을 조정함.


```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
# 결과가 좋아보인다. 특히 랜덤포레스트의 결과가 좋다.
```


```python
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

머신러닝의 이 방법은 __여러 기본 추정기의 예측을 결합해 모델의 품질을 향상__ 시킨다. 

## 고민해볼 것

조정 파라미터가 많은데 기본 매개변수를 조사하고 이런 매개변수 조정으로 모델의 품질에 어떤 의미가 있는지 생각해보자.

# 요리 추천 웹 앱 구축

데이터셋을 사용해 분류모델을 구축하고 Onnx의 웹을 활용해 저장된 모델을 사용하는 웹 앱을 개발할 것이다.

머신러닝의 가장 유용한 실제 용도 중 하나는 추천 시스템을 구축하는 것이다.

_We can take the first step in that direction today!_

## 연습문제 - 분류기 모델 훈련

먼저, 정리된 요리 데이터셋을 사용해 분류기 모델을 훈련해야한다.


```python
# skl2onnx설치 필요
!pip install skl2onnx
import pandas as pd 
```

    Collecting skl2onnx
      Downloading skl2onnx-1.11.1-py3-none-any.whl (276 kB)
    Collecting protobuf
      Downloading protobuf-3.20.1-cp39-cp39-win_amd64.whl (904 kB)
    Requirement already satisfied: scikit-learn>=0.19 in c:\users\pc\anaconda3\lib\site-packages (from skl2onnx) (1.0.2)
    Collecting onnx>=1.2.1
      Downloading onnx-1.11.0-cp39-cp39-win_amd64.whl (11.2 MB)
    Collecting onnxconverter-common>=1.7.0
      Downloading onnxconverter_common-1.9.0-py2.py3-none-any.whl (78 kB)
    Requirement already satisfied: scipy>=1.0 in c:\users\pc\anaconda3\lib\site-packages (from skl2onnx) (1.7.1)
    Requirement already satisfied: numpy>=1.15 in c:\users\pc\anaconda3\lib\site-packages (from skl2onnx) (1.20.3)
    Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\users\pc\anaconda3\lib\site-packages (from onnx>=1.2.1->skl2onnx) (3.10.0.2)
    Requirement already satisfied: joblib>=0.11 in c:\users\pc\anaconda3\lib\site-packages (from scikit-learn>=0.19->skl2onnx) (1.1.0)
    Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\pc\anaconda3\lib\site-packages (from scikit-learn>=0.19->skl2onnx) (2.2.0)
    Installing collected packages: protobuf, onnx, onnxconverter-common, skl2onnx
    Successfully installed onnx-1.11.0 onnxconverter-common-1.9.0 protobuf-3.20.1 skl2onnx-1.11.1
    


```python
# 데이터 불러오고 확인
data = pd.read_csv('cleaned_cuisines.csv')
data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>cuisine</th>
      <th>almond</th>
      <th>angelica</th>
      <th>anise</th>
      <th>anise_seed</th>
      <th>apple</th>
      <th>apple_brandy</th>
      <th>apricot</th>
      <th>armagnac</th>
      <th>...</th>
      <th>whiskey</th>
      <th>white_bread</th>
      <th>white_wine</th>
      <th>whole_grain_wheat_flour</th>
      <th>wine</th>
      <th>wood</th>
      <th>yam</th>
      <th>yeast</th>
      <th>yogurt</th>
      <th>zucchini</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>indian</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>indian</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 382 columns</p>
</div>




```python
# 필요없는 열을 지운 후 남은 데이터를 X에 저장한다.
X = data.iloc[:,2:]
X.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>almond</th>
      <th>angelica</th>
      <th>anise</th>
      <th>anise_seed</th>
      <th>apple</th>
      <th>apple_brandy</th>
      <th>apricot</th>
      <th>armagnac</th>
      <th>artemisia</th>
      <th>artichoke</th>
      <th>...</th>
      <th>whiskey</th>
      <th>white_bread</th>
      <th>white_wine</th>
      <th>whole_grain_wheat_flour</th>
      <th>wine</th>
      <th>wood</th>
      <th>yam</th>
      <th>yeast</th>
      <th>yogurt</th>
      <th>zucchini</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 380 columns</p>
</div>




```python
# 라벨은 y에 저장한다.
y = data[['cuisine']]
y.head()

```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cuisine</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>indian</td>
    </tr>
    <tr>
      <th>1</th>
      <td>indian</td>
    </tr>
    <tr>
      <th>2</th>
      <td>indian</td>
    </tr>
    <tr>
      <th>3</th>
      <td>indian</td>
    </tr>
    <tr>
      <th>4</th>
      <td>indian</td>
    </tr>
  </tbody>
</table>
</div>



### 훈련루틴 시작

SVC라이브러리를 사용할 것이다(정확도 좋음).


```python
# 필요 라이브러리import
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report
```


```python
# 데이터 나누기
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
```


```python
# SVC분류기 모델 구축하기
model = SVC(kernel='linear', C=10, probability=True,random_state=0)
model.fit(X_train,y_train.values.ravel())
```




    SVC(C=10, kernel='linear', probability=True, random_state=0)




```python
# 모델의 predict()를 사용해 예측해보자.
y_pred = model.predict(X_test)
```


```python
# 모델의 성능 출력
print(classification_report(y_test,y_pred))
```

                  precision    recall  f1-score   support
    
         chinese       0.69      0.76      0.72       264
          indian       0.86      0.89      0.88       227
        japanese       0.71      0.67      0.68       230
          korean       0.84      0.75      0.79       244
            thai       0.76      0.78      0.77       234
    
        accuracy                           0.77      1199
       macro avg       0.77      0.77      0.77      1199
    weighted avg       0.77      0.77      0.77      1199
    
    

## 모델을 Onnx로 변환

적절한 Tensor 번호로의 변환을 수행해야한다. 이 데이터셋에는 380개의 특성이 나열되어 있으므로 FloatTensorType에 해당 숫자를 표기해야 한다.


```python
# 380의 Tenser번호 사용해 변환
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType

initial_type = [('float_input', FloatTensorType([None, 380]))]
options = {id(model): {'nocl': True, 'zipmap': False}}
```


```python
# onx만들고 model.onnx의 파일 저장하기
onx = convert_sklearn(model, initial_types=initial_type, options=options)
with open("./model.onnx", "wb") as f:
    f.write(onx.SerializeToString())
```

> __주의할 점__
>
> 변환 스크립트에서 옵션을 전달할 수 있다. 이 경우 `nocl`을 `true`로ㅡ `zipmap`을 `false`로 한다.
>
> 이것은 분류모델이므로 사전 목록을 생성하는 ZipMap을 제겅하는 옵션이 있다. 이는 필수는 아니다.
>
>`nocl`을 `true`로 설정해 모델의 크기를 줄일 수 있다.

### 모델 살펴보기

Netron을 다운로드하고 저장한 `model.onnx`파일을 열면 380개의 입력 및 분류자가 나열된 간단한 모델이 시각화된 것을 볼 수 있다.

이제 우린 웹에서 모델을 사용할 준비가 되었다. 

우리가 만들 앱은 냉장고의 내용물을 볼 때 유용한 앱, 모델에 따라 원하는 요리를 요리할 때 사용할 수 있는 재료의 조합을 알아내는 앱이다.

### 추천 웹 앱 구축

웹 앱에서 직접 모델을 사용할 수 있다. 이 구조를 사용하면 로컬에서 실행할 수도 있고 필요한 경우 오프라인에서도 실행할 수 있다. `model.onnx` 파일을 저장한 동일한 폴더에 `index.html` 파일을 생성하여 시작하면 된다.

#### `index.html`


```python
<!DOCTYPE html>
<html>
    <header>
        <title>Cuisine Matcher</title>
    </header>
    <body>
        ...
    </body>
</html>
```

`body`태그 내에서 작업해 일부 구성요소를 반영하는 확인란 목록표시 마크업 추가

체크박스에 값이 지정된다.

데이터셋에 따라 재료가 발견된 인덱스를 반영한다. (Apple은 인덱스값이 4 : 0부터 계산시작해서)


```python
<h1>Check your refrigerator. What can you create?</h1>
        <div id="wrapper">
            <div class="boxCont">
                <input type="checkbox" value="4" class="checkbox">
                <label>apple</label>
            </div>
        
            <div class="boxCont">
                <input type="checkbox" value="247" class="checkbox">
                <label>pear</label>
            </div>
        
            <div class="boxCont">
                <input type="checkbox" value="77" class="checkbox">
                <label>cherry</label>
            </div>

            <div class="boxCont">
                <input type="checkbox" value="126" class="checkbox">
                <label>fenugreek</label>
            </div>

            <div class="boxCont">
                <input type="checkbox" value="302" class="checkbox">
                <label>sake</label>
            </div>

            <div class="boxCont">
                <input type="checkbox" value="327" class="checkbox">
                <label>soy sauce</label>
            </div>

            <div class="boxCont">
                <input type="checkbox" value="112" class="checkbox">
                <label>cumin</label>
            </div>
        </div>
        <div style="padding-top:10px">
            <button onClick="startInference()">What kind of cuisine can you make?</button>
        </div> 
```

이후 모델이 호출되는 블록을 추가해준다.


```python
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.9.0/dist/ort.min.js"></script> 
```


```python
<script>
    const ingredients = Array(380).fill(0);
    
    const checks = [...document.querySelectorAll('.checkbox')];
    
    checks.forEach(check => {
        check.addEventListener('change', function() {
            // toggle the state of the ingredient
            // based on the checkbox's value (1 or 0)
            ingredients[check.value] = check.checked ? 1 : 0;
        });
    });

    function testCheckboxes() {
        // validate if at least one checkbox is checked
        return checks.some(check => check.checked);
    }

    async function startInference() {

        let atLeastOneChecked = testCheckboxes()

        if (!atLeastOneChecked) {
            alert('Please select at least one ingredient.');
            return;
        }
        try {
            // create a new session and load the model.
            
            const session = await ort.InferenceSession.create('./model.onnx');

            const input = new ort.Tensor(new Float32Array(ingredients), [1, 380]);
            const feeds = { float_input: input };

            // feed inputs and run
            const results = await session.run(feeds);

            // read from results
            alert('You can enjoy ' + results.label.data[0] + ' cuisine today!')

        } catch (e) {
            console.log(`failed to inference ONNX model`);
            console.error(e);
        }
    }
           
</script>
```

위의 코드는 ....
1. 체크박스 확인란의 선택 여부에 따라 380개의 가능한 값(1또는0)의 배열을 생성하고 추론을 위해 모델로 전송함
2. 체크박스의 배열과 앱이 시작될 때 호출되는 추기화 함수에서 체크박스가 체크되었는지 확인하는 방법 만듬. (체크박스 선택 시 선택한 재료 반영하도록 재료 배열 변경)
3. 체크박스 선택되었는지 확인하는 `testCheckboxes()`함수 만듬
4. 버튼 누르면 `startInference()`기능 사용하고 체크박스 체크시 추론 시작

---

_추론 루틴에 포함되는 것_
- 모델의 비동기로드 설정
- 모델이 보낼 Tenser구조 만들기
- 모델 훈련시 생성한 float_input입력 반영하는 피드 생성(Netron을 사용하여 해당 이름을 확인할 수 있음)
- 이 '피드'를 모델에 보내고 응답을 기다림

---

❤️

앞서 말했듯 이는 [Getting started with classification ](https://github.com/codingalzi/ML-For-Beginners/tree/main/4-Classification/1-Introduction) 내용에 대한 학습과 정리에 대한 내용입니다.

더 자세한 내용이 필요하다면 링크를 참조해주세요.

감사합니다 🙂

❤️

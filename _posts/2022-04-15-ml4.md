---
title: '[Blog]타이타닉 데이터로 머신러닝'
layout: single
categories:
  - Python
tag:
  - Blog
  - machinelearning
  - assignment
toc: true
toc_label: "on this page"
toc_sticky: true
---
# Kaggle Titanic 데이터로 생존자 예측하기


```python
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import os
```

## 데이터 읽기

데이터를 읽기 전, 데이터를 먼저 받아와야한다. 
데이터를 받는 방법은 다음과 같다.
1. https://www.kaggle.com/competitions/titanic/data 사이트에 방문
2. 아래에 나와있는 train,test 파일 다운로드

위 사이트를 이용하면 보다 쉽게 타이타닉 데이터를 저장할 수 있다.


```python
import numpy as np
import pandas as pd

# 저장한 데이터를 불러온다.
train_data = pd.read_csv('train.csv')
test_data = pd.read_csv('test.csv')

# train_data의 앞부분을 살짝 살펴본다.
train_data.head()
```

train_data의 형태를 살펴보자


```python
train_data.shape
```

test_data의 형태를 살펴보자


```python
test_data.shape
```

훈련데이터셋의 생존자는 얼마나 있는지 확인할 수 있다.
Survived에서 0은 죽음을, 1은 생존을 나타낸다.


```python
train_data['Survived'].value_counts()
```


```python
#위를 시각화 한 것
import seaborn as sns
import matplotlib.pyplot as plt

f, ax=plt.subplots(1, 2, figsize=(18,8))
train_data['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)
ax[0].set_title('Survived')
ax[0].set_ylabel('')
sns.countplot('Survived',data=train_data,ax=ax[1])
ax[1].set_title('Survived')
plt.show()
```

성별과 객실 클래스에 대해서 생존자가 얼마나 되는지 알아보자.


```python
pd.crosstab([train_data['Sex'],train_data['Survived']],train_data['Pclass'],margins=True).style.background_gradient(cmap='summer_r')
```

위 표를 살펴보면 성별과 객실 클래스에 따라 얼마나 생존했고 하지 못했는지를 알 수 있다.


---
아래의 표는 각각 승객이 배를 탄 장소, 성별과 타이타닉 탑승 장소, 탑승장소와 생존 여부, 탑승장소와 객실 클래스에 따른 그래프이다.

이 그래프들을 통해 각 특성간 관계를 살펴볼 수 있다.


```python
f, ax = plt.subplots(2, 2, figsize=(20,15))

sns.countplot('Embarked', data=train_data,ax=ax[0,0])
ax[0,0].set_title('Passenger Boarded')

sns.countplot('Embarked',hue='Sex',data=train_data,ax=ax[0,1])
ax[0,1].set_title('Male-Female Split for Embarked')

sns.countplot('Embarked',hue='Survived',data=train_data,ax=ax[1,0])
ax[1,0].set_title('Embarked and Survived')

sns.countplot('Embarked',hue='Pclass',data=train_data,ax=ax[1,1])
ax[1,1].set_title('Embarked and Pclass')

plt.show()
```

## 전처리

우리는 훈련을 하기 전 누락된 값들을 채워주는 작업이 필요하다.

또한 훈련에 필요한 데이터들이 훈련될 수 있도록 필요에따라 데이터 타입을 변경해주는 일도 필요하다.


```python
train_test = [train_data, test_data]
```


```python
# ([A-Za-z]+).는 공백으로 시작하고 .으로 끝나는 문자열을 추출한다
for dataset in train_test:
    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\.')

train_data.head(5)
```


```python
# 성별을 Title로 구분지었다.
# 여기서 흔치 않은 Title을 Other로, 중복되는건 하나로 합칠 것이다.
pd.crosstab(train_data['Title'], train_data['Sex'])
```


```python
# Title과 그에 대한 생존율이 출력이다.
for dataset in train_test:    
    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Countess', 'Don','Dona', 'Dr', 'Jonkheer',
                                                 'Lady','Major', 'Rev', 'Sir'], 'Other')
    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')
    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')
    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')

train_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()
```

각 값들이 문자열로 저장될 수 있도록 돕 작업이다.


```python
for dataset in train_test:
    dataset['Title'] = dataset['Title'].astype(str)
```


```python
for dataset in train_test:
    dataset['Sex'] = dataset['Sex'].astype(str)
```

선착장에 대한 결측치를 확인해보자.


```python
train_data['Embarked'].value_counts(dropna=False)
```




    S      644
    C      168
    Q       77
    NaN      2
    Name: Embarked, dtype: int64




```python
# 항구의 결측치는 사람들이 가장 많이 이용한 항구로 채워준다
# 이는 결측 인원이 2명밖에 되지 않는 적은 수의 사람이라 가장 좋은 방법이라 생각된다.
for dataset in train_test:
    dataset['Embarked']=dataset['Embarked'].fillna('S')
    dataset['Embarked'] = dataset['Embarked'].astype(str)
train_data['Embarked'].value_counts(dropna=False)
```




    S    646
    C    168
    Q     77
    Name: Embarked, dtype: int64




```python
# 나이에 5가지 구간을 나누어 그룹을 만든 뒤 생존율 확인
# 이는 꼭 필요한 과정은 아니지만 데이터를 알아보는데에 유용하다.
for dataset in train_test:
    dataset['Age'].fillna(dataset['Age'].mean(), inplace=True)
    dataset['Age'] = dataset['Age'].astype(int)
    train_data['AgeBand'] = pd.cut(train_data['Age'], 5)
print (train_data[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean())
```

             AgeBand  Survived
    0  (-0.08, 16.0]  0.550000
    1   (16.0, 32.0]  0.344762
    2   (32.0, 48.0]  0.403226
    3   (48.0, 64.0]  0.434783
    4   (64.0, 80.0]  0.090909
    


```python
print (train_data[['Pclass', 'Fare']].groupby(['Pclass'], as_index=False).mean())
print("")

# 누락된 데이터의 좌석 등급을 알 수 있다.
print(test_data[test_data["Fare"].isnull()]["Pclass"])
```

       Pclass       Fare
    0       1  84.154687
    1       2  20.662183
    2       3  13.675550
    
    Series([], Name: Pclass, dtype: int64)
    

위에서 보이듯 `Fare`의 결측된 값의 `Pclass`는 3이다.

클래스 3의 평균 요금은 13.675550이다.


```python
# 이 누락된 값을 같은 좌석 등급의 평균 Fare(요금)로 바꿔줄 것이다.
for dataset in train_test:
    dataset['Fare'] = dataset['Fare'].fillna(13.675)
```


```python
# 이제 사용할 훈련셋과 테스트셋을 준비한다.
#필요한 데이터만을 남기고 꼭 필요한 데이터만을 각각의 세트에 저장한다.

features_drop = ['Name', 'Ticket', 'Cabin']

train = train_data.drop(features_drop, axis=1)
test = test_data.drop(features_drop, axis=1)

train = train.drop(['PassengerId', 'AgeBand'], axis=1)

print(train.head())
print(test.head())
```

       Survived  Pclass     Sex  Age  SibSp  Parch     Fare Embarked Title
    0         0       3    male   22      1      0   7.2500        S    Mr
    1         1       1  female   38      1      0  71.2833        C   Mrs
    2         1       3  female   26      0      0   7.9250        S  Miss
    3         1       1  female   35      1      0  53.1000        S   Mrs
    4         0       3    male   35      0      0   8.0500        S    Mr
       PassengerId  Pclass     Sex  Age  SibSp  Parch     Fare Embarked Title
    0          892       3    male   34      0      0   7.8292        Q    Mr
    1          893       3  female   47      1      0   7.0000        S   Mrs
    2          894       2    male   62      0      0   9.6875        Q    Mr
    3          895       3    male   27      0      0   8.6625        S    Mr
    4          896       3  female   22      1      1  12.2875        S   Mrs
    

원-핫-인코딩을 사용해 범주형 데이터를 수치형 데이터(0과 1)로 바꾼다.


```python
#원-핫-인코딩 사용
train = pd.get_dummies(train)
test = pd.get_dummies(test)

train_label = train['Survived']
train_data = train.drop('Survived', axis=1)
test_data = test.drop("PassengerId", axis=1).copy()
```

## 모델 설계 및 학습
예측모델은 Logistic Regression, Svm, kNN, Random Forest, Native Bayes를 사용해 볼 것이다.


```python
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB

from sklearn.utils import shuffle
```


```python
# 아래의 작업은 데이터를 섞는다.
# 이는 데이터의 정렬이 학습의 방해가 되는 것을 막는다.
train_data, train_label = shuffle(train_data, train_label, random_state = 5)
```


```python
# 파이프라인을 만든다. 

#모델을 입력하면
def train_and_test(model):
    
    #입력한 모델에 따라 훈련한다.
    model.fit(train_data, train_label)
    
    #예측값을 저장하고
    prediction = model.predict(test_data)
    
    #정확도를 측정한 뒤
    accuracy = round(model.score(train_data, train_label) * 100, 5)
    
    #정확도를 출력한다.
    print("Accuracy : ", accuracy, "%")
    return prediction
```


```python
# Logistic Regression
log_pred = train_and_test(LogisticRegression())
# SVM
svm_pred = train_and_test(SVC())
#kNN
knn_pred_4 = train_and_test(KNeighborsClassifier(n_neighbors = 4))
# Random Forest
rf_pred = train_and_test(RandomForestClassifier(n_estimators=100))
# Navie Bayes
nb_pred = train_and_test(GaussianNB())
```

    C:\Users\pc\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
    STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
    
    Increase the number of iterations (max_iter) or scale the data as shown in:
        https://scikit-learn.org/stable/modules/preprocessing.html
    Please also refer to the documentation for alternative solver options:
        https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
      n_iter_i = _check_optimize_result(
    

    Accuracy :  83.05275 %
    Accuracy :  68.68687 %
    Accuracy :  81.03255 %
    Accuracy :  97.86756 %
    Accuracy :  80.69585 %
    


```python
# DecisionTreeClassifier
# 위에 나오진 않았지만 추가적으로 결정트리모델도 사용해보자.
from sklearn.tree import DecisionTreeClassifier

train_and_test(DecisionTreeClassifier())
```

    Accuracy :  97.86756 %
    




    array([0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,
           1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,
           1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,
           1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,
           0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,
           0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,
           0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,
           0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,
           1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,
           0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,
           1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,
           0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,
           1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,
           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
           1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,
           1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,
           0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,
           1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,
           0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0],
          dtype=int64)



성능이 가장 좋은 모델은 `Random Forest`모델과 `DecisionTree`모델이었다.

나는 랜덤포레스트 모델로 제출하기로 결정했다.

제출을 위해선 위 내용을 모두 csv파일로 저장해야한다.

---
csv파일로 저장하는 방법은 다음과 같다.


```python
# 랜덤 포레스트 모델로 제출

submission = pd.DataFrame({
    "PassengerId": test["PassengerId"],
    "Survived": rf_pred
})

submission.to_csv('submission_rf.csv', index=False)
```
<center><img src="/assets/img/result.png" width="60%" height="70%" style=""></center>
위에서 만든 csv파일로 캐글 사이트에서 모델의 정확도에 대한 점수 등을 확인해보니 정확도에 대한 공적인 점수는 약 0.7(70%)가 나왔고 사람들 사이에서는 약 14,000명 중 1108등을 하였다.

좋다고 할 수 있는 결과인지는 모르겠으나 처음 도전을 하고 점수를 얻은 것에 만족한다!!
